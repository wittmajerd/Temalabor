{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPPn9aclwzKc",
        "outputId": "211ea14b-35ef-4275-d53f-1a193f876bf8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from glob import glob\n",
        "from typing import List\n",
        "from dataclasses import dataclass\n",
        "import pickle\n",
        "\n",
        "import statistics\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YBcbadtWw_7N"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Sign:\n",
        "  userID: int\n",
        "  genuine: bool\n",
        "  data: pd.DataFrame\n",
        "  feature_vector: np.ndarray\n",
        "  \n",
        "@dataclass\n",
        "class User:\n",
        "  userID: int\n",
        "  signatures: list[Sign]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deserialization of raw data\n",
        "with open('rawDevSigns.pkl', 'rb') as in_file:\n",
        "    devSigns = pickle.load(in_file)\n",
        "\n",
        "with open('rawEvalSigns.pkl', 'rb') as in_file:\n",
        "    evalSigns = pickle.load(in_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19004\n",
            "15696\n"
          ]
        }
      ],
      "source": [
        "print(len(devSigns))   # 19004\n",
        "print(len(evalSigns))  # 15696"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Features:\n",
        "\n",
        "1. **Duration:** The time taken to perform the signature, in seconds.\n",
        "1. **Width/Length:** This is the horizontal distance measured between the two most extreme points in the **X** direction.\n",
        "1. **Height:** This is the distance between the lowest point in a word and the highest point in a word. (**Y** coordinate)\n",
        "1. **Aspect ratio:** This is the ratio of the writing length to the writing height.\n",
        "1. **Pen-down ratio:** This is the ratio of the pen-down time to the total writing time. Calculation is performed by taking the ratio of the number of non-zero points to the total number of points.\n",
        "1. **Number of gaps/pen-ups:** The number of times the pen is lifted while signing after the first contact with the tablet and excluding the final pen-lift.\n",
        "\n",
        "1. **Component physical spacing:** Calculation involves taking the Euclidean distance between the last point sampled in a component and the first point sampled in the following component (if any). This value is calculated for each pen-up instance and averaged to obtain the final feature value.\n",
        "1. **Component time spacing:** This is the average duration of a pen-up instances in a signature.\n",
        "\n",
        "1. **Pressure**\n",
        "> - **mean tip pressure**\n",
        "> - **std of tip pressure**\n",
        "> - **min tip pressure**\n",
        "> - **max tip pressure**\n",
        "    \n",
        "10. **Velocity**\n",
        "> - **Horizontal velocity:** This is the average velocity over the **X** direction. It measures how fast the signature moves horizontally. This feature is calculated as the ratio of signature length to he duration of the signature.\n",
        "> - **Max velocity:** Calculation is performed in terms of component velocities vx and vy, calculated as the first derivative of the x and y streams respectively.\n",
        "> - **Average velocity**\n",
        "> - **Std of velocity**\n",
        "11. **Acceleration**\n",
        "> - Average absolute acceleration: The average absolute acceleration captures the mean rate of velocity change in both positive and negative directions.\n",
        "> - **Max acceleration**\n",
        "> - **Mean acceleration**\n",
        "> - **Std of acceleration**\n",
        "    \n",
        "12. **Number of strokes:** This feature is indicative of how many segments or states the handwriting goes through during the signature’s production. Calculated as\n",
        "1. **Curvature:** This is a measure of how “flat” or how “curved” the handwriting is. Curvature is calculated as the ratio of the signature path length to the word length. The path length is the sum of distances between each consecutive point in the sample (large number in the order of 10,000 pixels). The word length is the physical, or Euclidean, distance between the captured writing’s first and last point.\n",
        "1. **Average curvature per stroke:** The *curvature* value is calculated for each individual stroke in the handwriting sample, then averaged.\n",
        "1. **Cursitivity:** The ratio of the number of strokes to the number of pen-downs.\n",
        "1. **Cursiveness:** The ratio of the horizontal length of the handwriting to the number of pen-downs.\n",
        "\n",
        "1. **Top heaviness:** This is a measure of the proportion of the signature that lies above the vertical midpoint. This feature is calculated as the ratio of the number of points above the vertical midpoint to the total number of points. The midpoint can be calculated as mean and/or mode.\n",
        "1. **Horizontal dispersion:** This is a measure of the horizontal spread of the signature. It is calculated as the ratio of the number of points right to the horizontal midpoint of the signature to the total number of points. The midpoint can be calculated as mean and/or mode.\n",
        "\n",
        "Unused:  \n",
        "1. **Stroke concavity:** This measures how close the average stroke is to being a straight line. Calculation is performed using linear regression on the points in the stroke to obtain the line-of-best-fit. This measures how well the points in the stroke “fit” or approximate that line.\n",
        "1. **Mean ascender height:** This is the mean height of\n",
        "“ascenders” in the handwriting. \n",
        "Ascenders are letters such\n",
        "as ‘d’, ‘f’ and ‘t’ in which a part of the letter extends\n",
        "above the main body of the sample.\n",
        " Formal detection of ascenders in the body of a signature involves computing\n",
        "the mean of the data, as well as points at one quarter and\n",
        "three quarters of the maximum height. The ascender’s\n",
        "peaks are the local maxima in the y direction that are\n",
        "above the three quarter mark. \n",
        "The distance between a local maximum and the y mean is found and this distance\n",
        "is taken as the height of that ascender. The mean height\n",
        "for all ascenders is used as the value for this feature.\n",
        "1. **Descender depth:** Descenders are the opposite\n",
        "of ascenders. They are letters such as ‘g’, ‘y’ and ‘j’ that\n",
        "typically contain parts extending below the main body of\n",
        "the sample. Finding the descender extremities is\n",
        "done in a similar fashion to ascenders and uses the same\n",
        "frequency histogram. The descender extremities are the\n",
        "local minima in the y direction that fall below the lower\n",
        "quarter of the sample. The depth value for each extremity\n",
        "is measured as the distance between the local minimum\n",
        "and the y mean expressed as a positive integer.\n",
        "\n",
        "**Source:** Alan McCabe, Jarrod Trevathan and Wayne Read (2008) \"Neural Network-based Handwritten Signature Verification\"  \n",
        "        https://www.researchgate.net/publication/235993403_Neural_Network-based_Handwritten_Signature_Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stroke_detector(sign: pd.DataFrame):\n",
        "    # sign = original_sign.copy()\n",
        "    sign_np = sign.to_numpy()\n",
        "    # Calculate velocity and acceleration\n",
        "    x_vel = [0]\n",
        "    y_vel = [0]\n",
        "    vel = [0]\n",
        "    x_acc = [0]\n",
        "    y_acc = [0]\n",
        "    acc = [0]\n",
        "    \n",
        "    strokes = []\n",
        "    stroke = []\n",
        "    for i in range(1, len(sign)):\n",
        "        # calculate velocities\n",
        "        vx = (sign.x[i] - sign.x[i-1]) /10  # is /10 necessary?\n",
        "        vy = (sign.y[i] - sign.y[i-1]) /10\n",
        "        v = np.sqrt(vx**2 + vy**2)\n",
        "        x_vel.append(vx)\n",
        "        y_vel.append(vy)\n",
        "        vel.append(v)\n",
        "        # calculate accelerations\n",
        "        ax = vx - x_vel[i-1]\n",
        "        ay = vy - y_vel[i-1]\n",
        "        a = np.sqrt(ax**2 + ay**2)\n",
        "        x_acc.append(ax)\n",
        "        y_acc.append(ay)\n",
        "        acc.append(a)\n",
        "\n",
        "        # direction is the same\n",
        "        dot_product = x_vel[i] * x_vel[i-1] + y_vel[i] * y_vel[i-1]\n",
        "        # print(dot_product)\n",
        "        if(dot_product <= 0):\n",
        "            strokes.append(stroke)\n",
        "            stroke = []\n",
        "        stroke.append(sign_np[i])\n",
        "    strokes.append(stroke)\n",
        "    \n",
        "    sign['velocity'] = vel\n",
        "    sign['acceleration'] = acc\n",
        "    \n",
        "    return strokes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Curvature(sign):\n",
        "    word_length = np.sqrt((sign[0][0] - sign[len(sign)-1][0])**2 + (sign[0][1] - sign[len(sign)-1][1])**2)\n",
        "    path_length = 0\n",
        "    for i in range(1, len(sign)):\n",
        "        path_length += np.sqrt((sign[i][0] - sign[i-1][0])**2 + (sign[i][1] - sign[i-1][1])**2)\n",
        "    \n",
        "    return (path_length / word_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' Questions:\\n    Do we need a preprocess that removes dots, crossings and other fragments for some features?\\n    Rotation normalization??? baseline\\n'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\" Questions:\n",
        "    Do we need a preprocess that removes dots, crossings and other fragments for some features?\n",
        "    Rotation normalization??? baseline\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def FeatureExtraction(sign: pd.DataFrame) :\n",
        "    features = [] # np.ndarray?\n",
        "    # 1 duration of the signature is seconds\n",
        "    duration = sign['time'].iat[-1]/1000\n",
        "    features.append(duration)\n",
        "    # 2-4 Width, Height, Aspect Ratio\n",
        "    width = sign.x.max() - sign.x.min()\n",
        "    height = sign.y.max() - sign.y.min()\n",
        "    aspectRatio = width / height\n",
        "    features.append(width)\n",
        "    features.append(height)\n",
        "    features.append(aspectRatio)\n",
        "    # 5 pen down ratio\n",
        "    length = sign.shape[0]\n",
        "    zeroes = sign.value_counts(\"pressure\").get(0)\n",
        "    if zeroes == None:\n",
        "        zeroes = 0\n",
        "    penDownRatio = (length - zeroes) / length\n",
        "    features.append(penDownRatio)\n",
        "    # 6 number of gaps\n",
        "    # Itt talán jó lenne ki venni a kis pontokat, egyeneseket\n",
        "    gaps = 0\n",
        "    gap_lengths = []\n",
        "    path_length = 0\n",
        "    for i in range(1, length):\n",
        "        # Calculate path length here just for less for loops\n",
        "        path_length += np.sqrt((sign.x[i] - sign.x[i-1])**2 + (sign.y[i] - sign.y[i-1])**2)\n",
        "        \n",
        "        p = sign.pressure\n",
        "        begin = 0\n",
        "        if (p[i-1] > 0 and p[i] == 0):\n",
        "            gaps += 1\n",
        "            begin = i-1\n",
        "        elif (p[i-1] == 0 and p[i] > 0):\n",
        "            end = i\n",
        "            gap_length = np.sqrt((sign.x[end] - sign.x[begin])**2 + (sign.y[end] - sign.y[begin])**2)\n",
        "            gap_lengths.append(gap_length)\n",
        "    features.append(gaps)\n",
        "\n",
        "    # If there is no gap in the signature\n",
        "    if gaps > 0:\n",
        "        # 7 Component spacing\n",
        "        features.append(sum(gap_lengths) / gaps)\n",
        "        # 8 Component time spacing\n",
        "        features.append(zeroes / gaps)\n",
        "    else:\n",
        "        features.append(0)\n",
        "        features.append(0)\n",
        "    \n",
        "    # 9 mean, std, max, min pressure (nem tudom hogy kell-e mindegyik)\n",
        "    # Remove all rows where pressure is 0\n",
        "    signWOzeroes = sign.copy()\n",
        "    signWOzeroes = signWOzeroes[signWOzeroes.pressure > 0]\n",
        "    features.append(signWOzeroes.pressure.mean())\n",
        "    features.append(signWOzeroes.pressure.std())\n",
        "    features.append(signWOzeroes.pressure.min())\n",
        "    features.append(signWOzeroes.pressure.max())\n",
        "    \n",
        "    # Calculating velocity, acceleration and strokes\n",
        "    strokes = stroke_detector(sign)\n",
        "    \n",
        "    # 10-11 Velocity and acceleration features\n",
        "    # Horizontal velocity\n",
        "    horizontal_v = width / duration\n",
        "    features.append(horizontal_v)\n",
        "    \n",
        "    features.append(sign.velocity.max())\n",
        "    features.append(sign.velocity.mean())\n",
        "    features.append(sign.velocity.std())\n",
        "    # Average absolute acceleration?\n",
        "    features.append(sign.acceleration.max())\n",
        "    features.append(sign.acceleration.mean())\n",
        "    features.append(sign.acceleration.std())\n",
        "\n",
        "    # 12 Number of strokes\n",
        "    nb_strokes = len(strokes)\n",
        "    features.append(nb_strokes)\n",
        "    \n",
        "    # 13 Curvature\n",
        "    # Word length is the Euclidean distance between the captured writing’s first and last point\n",
        "    word_length = np.sqrt((sign.x[0] - sign.x[length-1])**2 + (sign.y[0] - sign.y[length-1])**2)\n",
        "    features.append(path_length / word_length)\n",
        "    # 14 Average curvature per stroke\n",
        "    # If the stroke is too short (0, 1 or 2) then we can't calulate the curvature\n",
        "    curvatures = []\n",
        "    for s in strokes:\n",
        "        if len(s) > 2:\n",
        "            curvatures.append(Curvature(s))\n",
        "        elif len(s) == 2:\n",
        "            curvatures.append(1)\n",
        "        else:\n",
        "            curvatures.append(0)\n",
        "    features.append(sum(curvatures) / len(curvatures))\n",
        "    # 15 Cursitivity\n",
        "    pendowns = gaps + 1\n",
        "    features.append(nb_strokes / pendowns)\n",
        "    # 16 Cursiveness\n",
        "    features.append(width / pendowns)\n",
        "    \n",
        "    # Using the sign without hovering points\n",
        "    # 17 Top heaviness\n",
        "    height_mean = signWOzeroes.y.mean()\n",
        "    # height_mode = max(set(sign.y), key=sign.y.count())\n",
        "    above = signWOzeroes[signWOzeroes.y > height_mean].shape[0]\n",
        "    features.append(above/length)\n",
        "    # 18 Horizontal dispersion\n",
        "    width_mean = signWOzeroes.x.mean()\n",
        "    # width_mode = max(set(sign.x), key=sign.x.count())\n",
        "    right = signWOzeroes[signWOzeroes.x > width_mean].shape[0]\n",
        "    features.append(right/length)\n",
        "    \n",
        "    # Not implemented:\n",
        "    # 19 Stroke concavity\n",
        "    \"\"\"\n",
        "    concavity = 0\n",
        "    for stroke in strokes:\n",
        "        # ri is the coordinate along the line-of-best-fit that is the least distance from si.\n",
        "        for i in range(len(stroke)):\n",
        "            concavity += (stroke[i] - r[i])**2\n",
        "    sqrt(concavity) \"\"\"\n",
        "    # 20 Mean ascender height\n",
        "    # height_three_quarters = sign.y.quantile(0.75)\n",
        "    # local maxima above this?\n",
        "    # 21 Mean descender depth\n",
        "    # height_one_quarter = sign.y.quantile(0.25)\n",
        "    \n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculating feature vectors for all signatures\n",
        "for sign in devSigns:\n",
        "    sign.feature_vector = FeatureExtraction(sign.data)\n",
        "\n",
        "for sign in evalSigns:\n",
        "    sign.feature_vector = FeatureExtraction(sign.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26\n"
          ]
        }
      ],
      "source": [
        "print(len(devSigns[0].feature_vector))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Serialize signatures with feature vectors\n",
        "with open('extractedDevSigns.pkl', 'wb') as out_file:\n",
        "    pickle.dump(devSigns, out_file)\n",
        "    \n",
        "with open('extractedEvalSigns.pkl', 'wb') as out_file:\n",
        "    pickle.dump(evalSigns, out_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deserialization of signatures with feature vectors\n",
        "with open('extractedDevSigns.pkl', 'rb') as in_file:\n",
        "    devSigns = pickle.load(in_file)\n",
        "\n",
        "with open('extractedEvalSigns.pkl', 'rb') as in_file:\n",
        "    evalSigns = pickle.load(in_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def SignaturesToUsers(inputSigns: List[Sign]) -> List[User]:\n",
        "    users = []\n",
        "    for i in range(inputSigns[0].userID, inputSigns[-1].userID+1):\n",
        "        userSigns = []\n",
        "        for sign in inputSigns:\n",
        "            if(sign.userID == i):\n",
        "                userSigns.append(sign)\n",
        "        users.append(User(userID=i,signatures=userSigns))\n",
        "        # print(User(userID=i,signatures=signs))\n",
        "    return users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assign each sign to its user\n",
        "devUsers = SignaturesToUsers(devSigns)\n",
        "evalUsers = SignaturesToUsers(evalSigns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "498\n",
            "50\n",
            "28\n",
            "372\n",
            "50\n",
            "28\n"
          ]
        }
      ],
      "source": [
        "print(len(devUsers))\n",
        "print(len(devUsers[50].signatures))\n",
        "print(len(devUsers[350].signatures))\n",
        "print(len(evalUsers))\n",
        "print(len(evalUsers[50].signatures))\n",
        "print(len(evalUsers[120].signatures))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Serialize users\n",
        "with open('devUsers.pkl', 'wb') as out_file:\n",
        "    pickle.dump(devUsers, out_file)\n",
        "    \n",
        "with open('evalUsers.pkl', 'wb') as out_file:\n",
        "    pickle.dump(evalUsers, out_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
