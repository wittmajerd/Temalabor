{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPPn9aclwzKc",
        "outputId": "211ea14b-35ef-4275-d53f-1a193f876bf8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "from dataclasses import dataclass\n",
        "import pickle\n",
        "import statistics\n",
        "import math\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Activation, Dropout, Input, concatenate\n",
        "from keras.callbacks import Callback, TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.utils import plot_model\n",
        "\n",
        "from keras import regularizers\n",
        "from keras.models import load_model\n",
        "from keras_visualizer import visualizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import seaborn as sns;\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YBcbadtWw_7N"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Sign:\n",
        "  userID: int\n",
        "  genuine: bool\n",
        "  data: pd.DataFrame\n",
        "  feature_vector: np.ndarray\n",
        "  \n",
        "@dataclass\n",
        "class User:\n",
        "  userID: int\n",
        "  signatures: list[Sign]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deserialization of all users   \n",
        "with open('allUsers.pkl', 'rb') as in_file:\n",
        "    all_users = pickle.load(in_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_data(users: List[User]):\n",
        "    data_length = 0\n",
        "    for user in users:\n",
        "        data_length += (len(user.signatures) - 4)\n",
        "    \n",
        "    X_list = np.ndarray(shape=(data_length, 4*26))\n",
        "    Y_list = np.ndarray(shape=(data_length, 1))\n",
        "    k = 0\n",
        "    \n",
        "    for user in users:\n",
        "        for i in range(4,len(user.signatures)):\n",
        "            X = []\n",
        "            for j in range(4):\n",
        "                # Simple difference, subtraction\n",
        "                # X_temp = np.subtract(user.signatures[i].feature_vector, user.signatures[j].feature_vector)\n",
        "                # Relative Difference is the best\n",
        "                X_temp = np.divide(np.subtract(user.signatures[i].feature_vector, user.signatures[j].feature_vector), np.add(np.add(user.signatures[i].feature_vector, user.signatures[j].feature_vector) / 2 , 1e-9))\n",
        "                # Relative Difference to the genuine signature\n",
        "                # X_temp = np.divide(np.subtract(user.signatures[i].feature_vector, user.signatures[j].feature_vector), np.add(user.signatures[j].feature_vector, 1e-9))\n",
        "                X.append(X_temp)\n",
        "                \n",
        "            X_list[k] = np.ndarray.flatten(np.array(X))\n",
        "            # 0 if the comparison is genuine, 1 if forged\n",
        "            Y = 0 if user.signatures[i].genuine else 1\n",
        "            Y_list[k] = Y\n",
        "            k += 1\n",
        "                \n",
        "    return X_list, Y_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Shuffling the users for better signature number distribution  \n",
        "Some users have 50 some 28 signatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "all_users = shuffle(all_users, random_state=1)  # Always shuffle with the same seed so that the results are reproducible"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Splitting the data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_users = all_users[:700]\n",
        "valid_users = all_users[700:800]\n",
        "test_users = all_users[800:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating the difference vectors for each datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25204, 104) (25204, 1) (3544, 104) (3544, 1) (2472, 104) (2472, 1)\n"
          ]
        }
      ],
      "source": [
        "X_train, Y_train = create_data(train_users)\n",
        "X_valid, Y_valid = create_data(valid_users)\n",
        "X_test, Y_test = create_data(test_users)\n",
        "print(X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape, X_test.shape, Y_test.shape)\n",
        "# Only fourth of the data as the single comparison "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The genuine and forged signature comparisons are balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.50789557] [0.5025395] [0.51294498]\n"
          ]
        }
      ],
      "source": [
        "# Forgery ratio in train, valid and test set\n",
        "print(sum(Y_train)/len(Y_train), sum(Y_valid)/len(Y_valid), sum(Y_test)/len(Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Standardizing the data if needed \n",
        "If the difference vectors are calculated with relative difference then the standardization is not neccecary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Building a different model\n",
        "There is four input for the model for each signature comparison\n",
        "Then we merge the results of the four comparisons and feed it to another dense layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_vector_size = len(all_users[0].signatures[0].feature_vector)\n",
        "\n",
        "activation = \"relu\"\n",
        "dropout = 0.5\n",
        "\n",
        "M1_in = Input(shape=(26,), name=\"M1_in\")\n",
        "M1 = Dense(200, activation=activation)(M1_in)\n",
        "M1 = Dropout(dropout)(M1)\n",
        "M1 = Dense(200, activation=activation)(M1)\n",
        "M1 = Dropout(dropout)(M1)\n",
        "M1 = Dense(200, activation=activation)(M1)\n",
        "M1 = Dropout(dropout)(M1)\n",
        "# M1 = Dense(200, activation=activation)(M1)\n",
        "# M1 = Dropout(dropout)(M1)\n",
        "M1 = Dense(50, activation=activation)(M1)\n",
        "\n",
        "M2_in = Input(shape=(26,), name=\"M2_in\")\n",
        "M2 = Dense(200, activation=activation)(M2_in)\n",
        "M2 = Dropout(dropout)(M2)\n",
        "M2 = Dense(200, activation=activation)(M2)\n",
        "M2 = Dropout(dropout)(M2)\n",
        "M2 = Dense(200, activation=activation)(M2)\n",
        "M2 = Dropout(dropout)(M2)\n",
        "# M2 = Dense(200, activation=activation)(M2)\n",
        "# M2 = Dropout(dropout)(M2)\n",
        "M2 = Dense(50, activation=activation)(M2)\n",
        "\n",
        "M3_in = Input(shape=(26,), name=\"M3_in\")\n",
        "M3 = Dense(200, activation=activation)(M3_in)\n",
        "M3 = Dropout(dropout)(M3)\n",
        "M3 = Dense(200, activation=activation)(M3)\n",
        "M3 = Dropout(dropout)(M3)\n",
        "M3 = Dense(200, activation=activation)(M3)\n",
        "M3 = Dropout(dropout)(M3)\n",
        "# M3 = Dense(200, activation=activation)(M3)\n",
        "# M3 = Dropout(dropout)(M3)\n",
        "M3 = Dense(50, activation=activation)(M3)\n",
        "\n",
        "M4_in = Input(shape=(26,), name=\"M4_in\")\n",
        "M4 = Dense(200, activation=activation)(M4_in)\n",
        "M4 = Dropout(dropout)(M4)\n",
        "M4 = Dense(200, activation=activation)(M4)\n",
        "M4 = Dropout(dropout)(M4)\n",
        "M4 = Dense(200, activation=activation)(M4)\n",
        "M4 = Dropout(dropout)(M4)\n",
        "# M4 = Dense(200, activation=activation)(M4)\n",
        "# M4 = Dropout(dropout)(M4)\n",
        "M4 = Dense(50, activation=activation)(M4)\n",
        "\n",
        "concat = concatenate([M1, M2, M3, M4])\n",
        "# dense = Dense(100, activation=activation)(concat)\n",
        "output_layer = Dense(1, activation=\"sigmoid\", name=\"output\")(concat)\n",
        "\n",
        "Merged = Model(inputs=[M1_in, M2_in, M3_in, M4_in], outputs=[output_layer])\n",
        "\n",
        "# plot_model(Merged, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.91704, saving model to weights.h5\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.21266, saving model to weights_loss.h5\n",
            "788/788 - 10s - loss: 0.2515 - accuracy: 0.9052 - val_loss: 0.2127 - val_accuracy: 0.9170 - lr: 0.0010 - 10s/epoch - 13ms/step\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2: val_accuracy improved from 0.91704 to 0.92946, saving model to weights.h5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.21266 to 0.17811, saving model to weights_loss.h5\n",
            "788/788 - 9s - loss: 0.1838 - accuracy: 0.9298 - val_loss: 0.1781 - val_accuracy: 0.9295 - lr: 0.0010 - 9s/epoch - 11ms/step\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.92946 to 0.93538, saving model to weights.h5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.17811 to 0.16672, saving model to weights_loss.h5\n",
            "788/788 - 8s - loss: 0.1634 - accuracy: 0.9378 - val_loss: 0.1667 - val_accuracy: 0.9354 - lr: 0.0010 - 8s/epoch - 11ms/step\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.93538\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.16672\n",
            "788/788 - 8s - loss: 0.1503 - accuracy: 0.9433 - val_loss: 0.1828 - val_accuracy: 0.9289 - lr: 0.0010 - 8s/epoch - 11ms/step\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.93538 to 0.93962, saving model to weights.h5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.16672 to 0.15751, saving model to weights_loss.h5\n",
            "788/788 - 8s - loss: 0.1435 - accuracy: 0.9459 - val_loss: 0.1575 - val_accuracy: 0.9396 - lr: 0.0010 - 8s/epoch - 10ms/step\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.93962\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.15751\n",
            "788/788 - 8s - loss: 0.1376 - accuracy: 0.9486 - val_loss: 0.1759 - val_accuracy: 0.9317 - lr: 0.0010 - 8s/epoch - 10ms/step\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.93962\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.15751\n",
            "788/788 - 8s - loss: 0.1325 - accuracy: 0.9496 - val_loss: 0.1694 - val_accuracy: 0.9320 - lr: 0.0010 - 8s/epoch - 11ms/step\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.93962\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.15751\n",
            "788/788 - 8s - loss: 0.1271 - accuracy: 0.9528 - val_loss: 0.1706 - val_accuracy: 0.9300 - lr: 0.0010 - 8s/epoch - 11ms/step\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.93962\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.15751\n",
            "788/788 - 8s - loss: 0.1252 - accuracy: 0.9537 - val_loss: 0.1666 - val_accuracy: 0.9382 - lr: 0.0010 - 8s/epoch - 10ms/step\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.93962\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.15751\n",
            "788/788 - 8s - loss: 0.1213 - accuracy: 0.9555 - val_loss: 0.1743 - val_accuracy: 0.9314 - lr: 0.0010 - 8s/epoch - 10ms/step\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.93962\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.15751\n",
            "788/788 - 8s - loss: 0.1154 - accuracy: 0.9590 - val_loss: 0.1747 - val_accuracy: 0.9326 - lr: 8.0000e-04 - 8s/epoch - 10ms/step\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.93962\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.15751\n",
            "788/788 - 8s - loss: 0.1112 - accuracy: 0.9598 - val_loss: 0.1896 - val_accuracy: 0.9269 - lr: 8.0000e-04 - 8s/epoch - 10ms/step\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.93962\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.15751\n",
            "788/788 - 8s - loss: 0.1077 - accuracy: 0.9610 - val_loss: 0.1788 - val_accuracy: 0.9343 - lr: 8.0000e-04 - 8s/epoch - 10ms/step\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.93962\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.15751\n",
            "788/788 - 8s - loss: 0.1061 - accuracy: 0.9600 - val_loss: 0.1911 - val_accuracy: 0.9289 - lr: 8.0000e-04 - 8s/epoch - 10ms/step\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.93962\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.15751\n",
            "788/788 - 8s - loss: 0.1014 - accuracy: 0.9631 - val_loss: 0.1951 - val_accuracy: 0.9249 - lr: 8.0000e-04 - 8s/epoch - 10ms/step\n",
            "Epoch 15: early stopping\n"
          ]
        }
      ],
      "source": [
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "Merged.compile(loss = {'output':'binary_crossentropy'}, optimizer = optimizer, metrics =['accuracy'])\n",
        "\n",
        "patience = 10\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=patience, verbose=1)\n",
        "checkpointer = ModelCheckpoint(monitor='val_accuracy', filepath='weights.h5', save_best_only=True, verbose=1)\n",
        "checkpointer2 = ModelCheckpoint(monitor='val_loss', filepath='weights_loss.h5', save_best_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.8, patience=5, min_lr=1e-7)\n",
        "\n",
        "fit_history = Merged.fit(\n",
        "            {'M1_in': X_train[:,:26], 'M2_in': X_train[:,26:52], 'M3_in': X_train[:,52:78], 'M4_in': X_train[:,78:]}, \n",
        "            {'output': Y_train},\n",
        "            batch_size=32,\n",
        "            epochs=50,\n",
        "            verbose=2,\n",
        "            validation_data=({'M1_in': X_valid[:,:26], 'M2_in': X_valid[:,26:52], 'M3_in': X_valid[:,52:78], 'M4_in': X_valid[:,78:]},\n",
        "                             {'output': Y_valid}),\n",
        "            callbacks=[ reduce_lr,\n",
        "                        checkpointer,\n",
        "                        checkpointer2,\n",
        "                        early_stopping],\n",
        "            shuffle= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "78/78 [==============================] - 0s 3ms/step - loss: 0.1800 - accuracy: 0.9324\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.18004031479358673, 0.932443380355835]"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = load_model('weights.h5')\n",
        "model.evaluate({'M1_in': X_test[:,:26], 'M2_in': X_test[:,26:52], 'M3_in': X_test[:,52:78], 'M4_in': X_test[:,78:]},\n",
        "                             {'output': Y_test})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "78/78 [==============================] - 0s 1000us/step\n",
            "Best Threshold=0.477355\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict({'M1_in': X_test[:,:26], 'M2_in': X_test[:,26:52], 'M3_in': X_test[:,52:78], 'M4_in': X_test[:,78:]})\n",
        "\n",
        "# Compute FAR and FRR\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, preds)\n",
        "far = fpr\n",
        "frr = 1 - tpr\n",
        "\n",
        "# Find the optimal threshold (EER)\n",
        "eer = thresholds[np.nanargmin(np.absolute((far - frr)))]\n",
        "\n",
        "print('Best Threshold=%f' % eer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of correct predictions: 2237\n",
            "Number of wrong predictions: 235\n",
            "Accuracy: 0.9049352750809061\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Text(0.5, 14.722222222222216, 'Predicted Label'),\n",
              " Text(33.22222222222222, 0.5, 'True label')]"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "preds_binary = np.where(preds > eer, 1, 0)\n",
        "conf = confusion_matrix(Y_test, preds_binary)\n",
        "# Compare the predictions with the actual values\n",
        "correct_preds = np.sum(preds_binary == Y_test)\n",
        "wrong_preds = len(Y_test) - correct_preds\n",
        "\n",
        "print(f\"Number of correct predictions: {correct_preds}\")\n",
        "print(f\"Number of wrong predictions: {wrong_preds}\")\n",
        "print(f\"Accuracy: {accuracy_score(Y_test, preds_binary)}\")\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "ax = sns.heatmap(conf, annot=True, fmt='d', cmap=plt.cm.Blues)\n",
        "ax.set(xlabel='Predicted Label',\n",
        "       ylabel='True label')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
